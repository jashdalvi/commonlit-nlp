{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"execution":{"iopub.execute_input":"2023-07-29T12:42:41.733397Z","iopub.status.busy":"2023-07-29T12:42:41.733043Z","iopub.status.idle":"2023-07-29T12:42:56.639283Z","shell.execute_reply":"2023-07-29T12:42:56.638359Z","shell.execute_reply.started":"2023-07-29T12:42:41.733367Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n","  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n","/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:98: UserWarning: unable to load libtensorflow_io_plugins.so: unable to open file: libtensorflow_io_plugins.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so']\n","caused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so: undefined symbol: _ZN3tsl6StatusC1EN10tensorflow5error4CodeESt17basic_string_viewIcSt11char_traitsIcEENS_14SourceLocationE']\n","  warnings.warn(f\"unable to load libtensorflow_io_plugins.so: {e}\")\n","/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:104: UserWarning: file system plugins are not loaded: unable to open file: libtensorflow_io.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so']\n","caused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so: undefined symbol: _ZTVN10tensorflow13GcsFileSystemE']\n","  warnings.warn(f\"file system plugins are not loaded: {e}\")\n"]},{"name":"stdout","output_type":"stream","text":["env: TOKENIZERS_PARALLELISM=true\n"]}],"source":["import torch\n","import torch.nn as nn\n","import numpy as np\n","import os\n","import transformers\n","from transformers import AutoModel, AutoConfig, AutoTokenizer, get_cosine_schedule_with_warmup, get_polynomial_decay_schedule_with_warmup, get_linear_schedule_with_warmup, get_cosine_with_hard_restarts_schedule_with_warmup\n","import pandas as pd\n","from torch.cuda.amp import autocast, GradScaler\n","from sklearn.metrics import mean_squared_error\n","import random\n","import time\n","from torch.utils import checkpoint\n","import math\n","import gc\n","from typing import Dict, List, Tuple\n","import codecs\n","import warnings\n","import torch.nn.functional as F\n","from dataclasses import dataclass, field, asdict\n","import wandb\n","from tqdm import tqdm\n","transformers.logging.set_verbosity_error()\n","warnings.filterwarnings(\"ignore\")\n","\n","%env TOKENIZERS_PARALLELISM=true\n","\n","# declare the two GPUs\n","os.environ['CUDA_VISIBLE_DEVICES'] = \"0,1\"\n","\n","# avoids some issues when using more than one worker\n","os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\""]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2023-07-29T12:42:56.642443Z","iopub.status.busy":"2023-07-29T12:42:56.641755Z","iopub.status.idle":"2023-07-29T12:42:56.734251Z","shell.execute_reply":"2023-07-29T12:42:56.733260Z","shell.execute_reply.started":"2023-07-29T12:42:56.642409Z"},"trusted":true},"outputs":[],"source":["@dataclass\n","class cfg:\n","    train_summary_file: str = field(default=\"/kaggle/input/commonlit-evaluate-student-summaries/summaries_train.csv\", metadata={\"help\": \"train file path\"})\n","    train_prompt_file: str = field(default=\"/kaggle/input/commonlit-evaluate-student-summaries/prompts_train.csv\", metadata={\"help\": \"train file path\"})\n","    batch_size: int = field(default=16, metadata={\"help\": \"batch size\"})\n","    epochs: int = field(default=4, metadata={\"help\": \"number of epochs\"})\n","    lr: float = field(default=2e-5, metadata={\"help\": \"learning rate\"})\n","    max_len: int = field(default=512, metadata={\"help\": \"max length of input\"})\n","    model_name: str = field(default=\"microsoft/deberta-v3-base\", metadata={\"help\": \"model name\"})\n","    hidden_dropout_prob: float = field(default=0.0, metadata={\"help\": \"hidden dropout probability\"})\n","    layer_norm_eps: float = field(default=1e-7, metadata={\"help\": \"layer norm eps\"})\n","    gradient_accumulation_steps: int = field(default=1, metadata={\"help\": \"gradient accumulation steps\"})\n","    gradient_checkpointing_enable: bool = field(default=False, metadata={\"help\": \"gradient checkpointing\"})\n","    warmup_ratio: float = field(default=0.1, metadata={\"help\": \"warmup ratio\"})\n","    max_grad_norm: float = field(default=10.0, metadata={\"help\": \"max grad norm\"})\n","    target_columns: List[str] = field(default = ('content', 'wording'), metadata={\"help\": \"target columns\"})\n","    num_classes: int = field(default=2, metadata={\"help\": \"number of classes\"})\n","    seed: int = field(default=42, metadata={\"help\": \"seed\"})\n","    device: str = field(default=\"cuda\" if torch.cuda.is_available() else \"cpu\", metadata={\"help\": \"device\"})\n","    multi_gpu: bool = field(default=torch.cuda.device_count() > 1, metadata={\"help\": \"multi gpu\"})\n","    use_wandb: bool = field(default=True, metadata={\"help\": \"use wandb for logging\"})\n","    project_name: str = field(default=\"commonlit-kaggle\", metadata={\"help\": \"wandb project name\"})"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2023-07-29T12:42:56.737024Z","iopub.status.busy":"2023-07-29T12:42:56.736370Z","iopub.status.idle":"2023-07-29T12:43:02.370542Z","shell.execute_reply":"2023-07-29T12:43:02.369492Z","shell.execute_reply.started":"2023-07-29T12:42:56.736990Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n","\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n","\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:"]},{"name":"stdout","output_type":"stream","text":["  ········································\n"]},{"name":"stderr","output_type":"stream","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"]},{"data":{"text/plain":["True"]},"execution_count":3,"metadata":{},"output_type":"execute_result"}],"source":["wandb.login()"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2023-07-29T12:43:02.374477Z","iopub.status.busy":"2023-07-29T12:43:02.373417Z","iopub.status.idle":"2023-07-29T12:43:02.380085Z","shell.execute_reply":"2023-07-29T12:43:02.379061Z","shell.execute_reply.started":"2023-07-29T12:43:02.374445Z"},"trusted":true},"outputs":[],"source":["def seed_everything(seed=cfg.seed):\n","    random.seed(seed)\n","    os.environ['PYTHONHASHSEED'] = str(seed)\n","    np.random.seed(seed)\n","    torch.manual_seed(seed)\n","    torch.cuda.manual_seed(seed)\n","    torch.backends.cudnn.deterministic = True"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2023-07-29T12:43:02.382725Z","iopub.status.busy":"2023-07-29T12:43:02.381722Z","iopub.status.idle":"2023-07-29T12:43:02.408569Z","shell.execute_reply":"2023-07-29T12:43:02.407315Z","shell.execute_reply.started":"2023-07-29T12:43:02.382690Z"},"trusted":true},"outputs":[],"source":["#Utiliy functions \n","class AverageMeter(object):\n","    \"\"\"Computes and stores the average and current value\"\"\"\n","    def __init__(self):\n","        self.reset()\n","\n","    def reset(self):\n","        self.val = 0\n","        self.avg = 0\n","        self.sum = 0\n","        self.count = 0\n","\n","    def update(self, val, n=1):\n","        self.val = val\n","        self.sum += val * n\n","        self.count += n\n","        self.avg = self.sum / self.count\n","\n","def compute_mcrmse(preds, labels):\n","    \"\"\"\n","    Calculates mean columnwise root mean squared error\n","    https://www.kaggle.com/competitions/commonlit-evaluate-student-summaries/overview/evaluation\n","    \"\"\"\n","\n","    col_rmse = np.sqrt(np.mean((preds - labels) ** 2, axis=0))\n","    mcrmse = np.mean(col_rmse)\n","\n","    return {\n","        \"content_rmse\": col_rmse[0],\n","        \"wording_rmse\": col_rmse[1],\n","        \"mcrmse\": mcrmse,\n","    }"]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2023-07-29T12:43:02.411830Z","iopub.status.busy":"2023-07-29T12:43:02.410685Z","iopub.status.idle":"2023-07-29T12:43:02.425019Z","shell.execute_reply":"2023-07-29T12:43:02.424030Z","shell.execute_reply.started":"2023-07-29T12:43:02.411793Z"},"trusted":true},"outputs":[],"source":["class Collate:\n","    \"\"\"Data collator for training and improving efficiency\"\"\"\n","    def __init__(self, tokenizer):\n","        self.tokenizer = tokenizer\n","        \n","    def __call__(self, batch):\n","        \n","        batch_len = max([len(sample[\"ids\"]) for sample in batch])\n","        \n","        output = dict()\n","        output[\"ids\"] = [sample[\"ids\"] for sample in batch]\n","        output[\"mask\"] = [sample[\"mask\"] for sample in batch]\n","        output[\"targets\"] = [sample[\"targets\"] for sample in batch]\n","        \n","        if self.tokenizer.padding_side == \"right\":\n","            output[\"ids\"] = [s + [self.tokenizer.pad_token_id] * (batch_len - len(s)) for s in output[\"ids\"]]\n","            output[\"mask\"] = [s + [0] * (batch_len - len(s)) for s in output[\"mask\"]]\n","        else:\n","            output[\"ids\"] = [[self.tokenizer.pad_token_id] * (batch_len - len(s)) + s for s in output[\"ids\"]]\n","            output[\"mask\"] = [[0] * (batch_len - len(s)) + s for s in output[\"mask\"]]\n","            \n","            \n","        output[\"ids\"] = torch.tensor(output[\"ids\"], dtype = torch.long)\n","        output[\"mask\"] = torch.tensor(output[\"mask\"], dtype = torch.long)\n","        output[\"targets\"] = torch.tensor(output[\"targets\"], dtype = torch.float32)\n","        \n","        return output"]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2023-07-29T12:43:02.428167Z","iopub.status.busy":"2023-07-29T12:43:02.427736Z","iopub.status.idle":"2023-07-29T12:43:02.441835Z","shell.execute_reply":"2023-07-29T12:43:02.440600Z","shell.execute_reply.started":"2023-07-29T12:43:02.428115Z"},"trusted":true},"outputs":[],"source":["class Dataset(torch.utils.data.Dataset):\n","    \"\"\"Pytorch dataset class for tokenizing the text and targets\"\"\"\n","    def __init__(self, texts, targets, tokenizer):\n","        self.texts = texts\n","        self.targets = targets\n","        self.tokenizer = tokenizer\n","        \n","    def __len__(self):\n","        return len(self.texts)\n","    \n","    def __getitem__(self, idx):\n","        \n","        text = self.texts[idx]\n","        targets = self.targets[idx]\n","        encoding = self.tokenizer(text, add_special_tokens = True, max_length = cfg.max_len, padding = False, truncation = 'longest_first') \n","        \n","        return {\n","            \"ids\": encoding[\"input_ids\"], \n","            \"mask\": encoding[\"attention_mask\"],\n","            \"targets\": targets\n","        }"]},{"cell_type":"code","execution_count":8,"metadata":{"execution":{"iopub.execute_input":"2023-07-29T12:43:02.443706Z","iopub.status.busy":"2023-07-29T12:43:02.443349Z","iopub.status.idle":"2023-07-29T12:43:02.454501Z","shell.execute_reply":"2023-07-29T12:43:02.453462Z","shell.execute_reply.started":"2023-07-29T12:43:02.443676Z"},"trusted":true},"outputs":[],"source":["class Model(nn.Module):\n","    \"\"\"Model class\"\"\"\n","    def __init__(self, model_name):\n","        super().__init__()\n","\n","        self.model_name = model_name\n","        config = AutoConfig.from_pretrained(model_name)\n","\n","        config.update(\n","            {\n","                \"output_hidden_states\": True,\n","                \"hidden_dropout_prob\": cfg.hidden_dropout_prob,\n","                \"attention_probs_dropout_prob\" : cfg.hidden_dropout_prob,\n","                \"layer_norm_eps\": cfg.layer_norm_eps,\n","                \"add_pooling_layer\": False,\n","                \"num_labels\": cfg.num_classes,\n","            }\n","        )\n","        \n","        self.config = config\n","        \n","        self.transformer = AutoModel.from_pretrained(model_name, config=config)\n","        if cfg.gradient_checkpointing_enable:\n","            self.transformer.gradient_checkpointing_enable()\n","        \n","        self.output = nn.Linear(config.hidden_size, cfg.num_classes)\n","    \n","    def forward(self, ids, mask, targets = None):\n","        transformer_out = self.transformer(input_ids = ids, attention_mask = mask)\n","        logits = self.output(transformer_out.last_hidden_state[:,0,:])\n","        return logits"]},{"cell_type":"code","execution_count":9,"metadata":{"execution":{"iopub.execute_input":"2023-07-29T12:43:02.458269Z","iopub.status.busy":"2023-07-29T12:43:02.457867Z","iopub.status.idle":"2023-07-29T12:43:02.478192Z","shell.execute_reply":"2023-07-29T12:43:02.477187Z","shell.execute_reply.started":"2023-07-29T12:43:02.458245Z"},"trusted":true},"outputs":[],"source":["def criterion(inputs, targets):\n","    return nn.MSELoss()(inputs, targets)\n","\n","def get_optimizer_scheduler(model, num_train_steps):\n","    \"\"\"get optimizer and scheduler\"\"\"\n","    no_decay = [\"bias\", \"LayerNorm.weight\"]\n","    optimizer_params = [\n","        {\n","            \"params\": [p for n, p in model.named_parameters() if not any(nd in n for nd in no_decay)],\n","            \"weight_decay\": 0.001,\n","            \"lr\" : cfg.lr\n","        },\n","        {\n","            \"params\": [p for n, p in model.named_parameters() if any(nd in n for nd in no_decay)],\n","            \"weight_decay\": 0.0,\n","            \"lr\" : cfg.lr\n","        }\n","    ]\n","    optimizer = torch.optim.AdamW(optimizer_params, lr=cfg.lr)\n","    scheduler = get_cosine_schedule_with_warmup(\n","            optimizer,\n","            num_warmup_steps=int(num_train_steps * cfg.warmup_ratio),\n","            num_training_steps=num_train_steps,\n","            last_epoch=-1,\n","    )\n","    return optimizer, scheduler\n","\n","def train(epoch, model, train_loader, valid_loader, optimizer, scheduler, device, scaler):\n","    \"\"\"training pass\"\"\"\n","    model.train()\n","    losses = AverageMeter()\n","\n","    for batch_idx, (batch) in tqdm(enumerate(train_loader), total = len(train_loader)):\n","        for k, v in batch.items():\n","            batch[k] = v.to(device)\n","        \n","        with autocast():\n","            outputs = model(**batch)\n","            loss = criterion(outputs, batch[\"targets\"])\n","        \n","        if cfg.gradient_accumulation_steps > 1:\n","            loss = loss / cfg.gradient_accumulation_steps\n","        \n","        losses.update(loss.item() * cfg.gradient_accumulation_steps , cfg.batch_size)\n","        scaler.scale(loss).backward()\n","\n","        if (batch_idx + 1) % cfg.gradient_accumulation_steps == 0:\n","            scaler.unscale_(optimizer)\n","            torch.nn.utils.clip_grad_norm_(model.parameters(), cfg.max_grad_norm)\n","            scaler.step(optimizer)\n","            scaler.update()\n","            optimizer.zero_grad()\n","            if scheduler is not None:\n","                scheduler.step()\n","\n","        if cfg.use_wandb:\n","            wandb.log({\n","                \"train/loss\": losses.val,\n","                \"train/lr\": scheduler.get_last_lr()[0],\n","                \"train/step\": epoch * len(train_loader) + batch_idx,\n","\n","            })\n","    \n","    return losses.avg\n","\n","@torch.no_grad()\n","def evaluate(epoch, model, valid_loader, device):\n","    \"\"\"evaluate pass\"\"\"\n","    model.eval()\n","    all_targets = []\n","    all_outputs = []\n","    losses = AverageMeter()\n","\n","    for batch_idx, (batch) in tqdm(enumerate(valid_loader), total = len(valid_loader)):\n","        for k, v in batch.items():\n","            batch[k] = v.to(device)\n","        \n","        outputs = model(**batch)\n","        loss = criterion(outputs, batch[\"targets\"])\n","        losses.update(loss.item(), cfg.batch_size)\n","        all_targets.extend(batch[\"targets\"].detach().cpu().numpy())\n","        all_outputs.extend(outputs.cpu().numpy())\n","    \n","    all_targets = np.vstack(all_targets)\n","    all_outputs = np.vstack(all_outputs)\n","    score = compute_mcrmse(all_outputs, all_targets)\n","    return score, losses.avg"]},{"cell_type":"code","execution_count":10,"metadata":{"execution":{"iopub.execute_input":"2023-07-29T12:43:02.482210Z","iopub.status.busy":"2023-07-29T12:43:02.481746Z","iopub.status.idle":"2023-07-29T12:43:02.500715Z","shell.execute_reply":"2023-07-29T12:43:02.499498Z","shell.execute_reply.started":"2023-07-29T12:43:02.482184Z"},"trusted":true},"outputs":[],"source":["def main(fold, seed):\n","    \"\"\"Main loop\"\"\"\n","    # Seed everything\n","    seed_everything(seed=seed)\n","    if cfg.use_wandb:\n","        run = wandb.init(project=cfg.project_name, \n","                         config=asdict(cfg()), \n","                         group = cfg.model_name, \n","                         reinit=True)\n","        wandb.define_metric(\"train/step\")\n","        wandb.define_metric(\"valid/step\")\n","        # define which metrics will be plotted against it\n","        wandb.define_metric(\"train/*\", step_metric=\"train/step\")\n","        wandb.define_metric(\"valid/*\", step_metric=\"valid/step\")\n","    \n","    pdf = pd.read_csv(cfg.train_prompt_file)\n","    sdf = pd.read_csv(cfg.train_summary_file)\n","    df = pdf.merge(sdf, on=\"prompt_id\")\n","\n","    # 4 prompt ids, 4 folds\n","    id2fold = {\n","        \"39c16e\": 0,\n","        \"814d6b\": 1,\n","        \"3b9047\": 2,\n","        \"ebad26\": 3,\n","    }\n","    df[\"fold\"] = df[\"prompt_id\"].map(id2fold)\n","\n","    train_df = df[df[\"fold\"] != fold].reset_index(drop=True)\n","    valid_df = df[df[\"fold\"] == fold].reset_index(drop=True)\n","\n","    tokenizer = AutoTokenizer.from_pretrained(cfg.model_name)\n","    sep_token = tokenizer.sep_token\n","\n","    # Preparing the train texts and targets\n","    train_texts = train_df[\"text\"].to_list()\n","    valid_texts = valid_df[\"text\"].to_list()\n","    train_targets = train_df[list(cfg.target_columns)].values.tolist()\n","    valid_targets = valid_df[list(cfg.target_columns)].values.tolist()\n","\n","    # Preparing the datasets and dataloaders\n","    collate_fn = Collate(tokenizer)\n","    train_ds = Dataset(train_texts, train_targets, tokenizer)\n","    valid_ds = Dataset(valid_texts, valid_targets, tokenizer)\n","\n","    train_loader = torch.utils.data.DataLoader(\n","        train_ds, \n","        batch_size = cfg.batch_size, \n","        shuffle = True, \n","        collate_fn = collate_fn)\n","\n","    valid_loader = torch.utils.data.DataLoader(\n","        valid_ds,\n","        batch_size = cfg.batch_size,\n","        shuffle = False,\n","        collate_fn = collate_fn)\n","    \n","    # Preparing the model\n","    model = Model(cfg.model_name)\n","    model = model.to(cfg.device)\n","    if cfg.use_wandb:\n","        wandb.watch(model)\n","    \n","    if cfg.multi_gpu:\n","        model = nn.DataParallel(model)\n","    \n","    num_train_steps = int(len(train_ds) / cfg.batch_size / cfg.gradient_accumulation_steps * cfg.epochs)\n","    optimizer, scheduler = get_optimizer_scheduler(model.module, num_train_steps)\n","\n","    scaler = GradScaler()\n","    # Training loop\n","    best_score = 1\n","    for epoch in range(cfg.epochs):\n","        train_loss = train(epoch, model, train_loader, valid_loader, optimizer, scheduler, cfg.device, scaler)\n","        valid_score, valid_loss = evaluate(epoch, model, valid_loader, cfg.device)\n","        if cfg.use_wandb:\n","            wandb.log({\"valid/train_loss_avg\": train_loss, \n","                       \"valid/valid_loss_avg\": valid_loss, \n","                       \"valid/mcrmse\": valid_score[\"mcrmse\"],\n","                       \"valid/content_rmse\": valid_score[\"content_rmse\"],\n","                       \"valid/wording_rmse\": valid_score[\"wording_rmse\"], \n","                       \"valid/step\": epoch})\n","        \n","        if valid_score[\"mcrmse\"] < best_score:\n","            best_score = valid_score[\"mcrmse\"]\n","            if cfg.multi_gpu:\n","                torch.save(model.module.state_dict(), f\"{cfg.model_name.split(os.path.sep)[-1]}_fold{fold}_seed{cfg.seed}.bin\")\n","            else:\n","                torch.save(model.state_dict(), f\"{cfg.model_name.split(os.path.sep)[-1]}_fold{fold}_seed{cfg.seed}.bin\")\n","    \n","    if cfg.use_wandb:\n","        run.finish()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-07-29T12:43:02.502653Z","iopub.status.busy":"2023-07-29T12:43:02.502280Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mjashdalvi99\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"]},{"data":{"text/html":["wandb version 0.15.7 is available!  To upgrade, please run:\n"," $ pip install wandb --upgrade"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Tracking run with wandb version 0.15.5"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Run data is saved locally in <code>/kaggle/working/wandb/run-20230729_124302-fbwfzfue</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Syncing run <strong><a href='https://wandb.ai/jashdalvi99/commonlit-kaggle/runs/fbwfzfue' target=\"_blank\">kind-wind-5</a></strong> to <a href='https://wandb.ai/jashdalvi99/commonlit-kaggle' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View project at <a href='https://wandb.ai/jashdalvi99/commonlit-kaggle' target=\"_blank\">https://wandb.ai/jashdalvi99/commonlit-kaggle</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run at <a href='https://wandb.ai/jashdalvi99/commonlit-kaggle/runs/fbwfzfue' target=\"_blank\">https://wandb.ai/jashdalvi99/commonlit-kaggle/runs/fbwfzfue</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"7372b02ce40c4573adbfd1d16eed6a03","version_major":2,"version_minor":0},"text/plain":["Downloading (…)okenizer_config.json:   0%|          | 0.00/52.0 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"faace16a0d804864989c181291170715","version_major":2,"version_minor":0},"text/plain":["Downloading (…)lve/main/config.json:   0%|          | 0.00/579 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"7249e659df1c4fb5984ea866e540ca72","version_major":2,"version_minor":0},"text/plain":["Downloading spm.model:   0%|          | 0.00/2.46M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"294a377f4c0e4fefb769c3ff9643fab8","version_major":2,"version_minor":0},"text/plain":["Downloading pytorch_model.bin:   0%|          | 0.00/371M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":[" 11%|█         | 35/320 [00:25<02:20,  2.03it/s]"]}],"source":["main(0, cfg.seed)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.16"}},"nbformat":4,"nbformat_minor":4}
