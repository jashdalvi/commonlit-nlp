{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "/Users/jashdalvi/miniforge3/envs/ml/lib/python3.9/site-packages/transformers/convert_slow_tokenizer.py:446: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n",
      "  warnings.warn(\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"microsoft/deberta-v3-large\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_prompt_file = \"../data/prompts_train.csv\"\n",
    "train_summary_file = \"../data/summaries_train.csv\"\n",
    "pdf = pd.read_csv(train_prompt_file)\n",
    "sdf = pd.read_csv(train_summary_file)\n",
    "df = pdf.merge(sdf, on=\"prompt_id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prompt_id</th>\n",
       "      <th>prompt_question</th>\n",
       "      <th>prompt_title</th>\n",
       "      <th>prompt_text</th>\n",
       "      <th>student_id</th>\n",
       "      <th>text</th>\n",
       "      <th>content</th>\n",
       "      <th>wording</th>\n",
       "      <th>corrected_text</th>\n",
       "      <th>fold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39c16e</td>\n",
       "      <td>Summarize at least 3 elements of an ideal trag...</td>\n",
       "      <td>On Tragedy</td>\n",
       "      <td>Chapter 13 \\r\\nAs the sequel to what has alrea...</td>\n",
       "      <td>00791789cc1f</td>\n",
       "      <td>1 element of an ideal tragedy is that it shoul...</td>\n",
       "      <td>-0.210614</td>\n",
       "      <td>-0.471415</td>\n",
       "      <td>One element of an ideal tragedy is that it sho...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>39c16e</td>\n",
       "      <td>Summarize at least 3 elements of an ideal trag...</td>\n",
       "      <td>On Tragedy</td>\n",
       "      <td>Chapter 13 \\r\\nAs the sequel to what has alrea...</td>\n",
       "      <td>0086ef22de8f</td>\n",
       "      <td>The three elements of an ideal tragedy are:  H...</td>\n",
       "      <td>-0.970237</td>\n",
       "      <td>-0.417058</td>\n",
       "      <td>The three elements of an ideal tragedy are  Ha...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>39c16e</td>\n",
       "      <td>Summarize at least 3 elements of an ideal trag...</td>\n",
       "      <td>On Tragedy</td>\n",
       "      <td>Chapter 13 \\r\\nAs the sequel to what has alrea...</td>\n",
       "      <td>0094589c7a22</td>\n",
       "      <td>Aristotle states that an ideal tragedy should ...</td>\n",
       "      <td>-0.387791</td>\n",
       "      <td>-0.584181</td>\n",
       "      <td>Aristotle states that an ideal tragedy should ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>39c16e</td>\n",
       "      <td>Summarize at least 3 elements of an ideal trag...</td>\n",
       "      <td>On Tragedy</td>\n",
       "      <td>Chapter 13 \\r\\nAs the sequel to what has alrea...</td>\n",
       "      <td>00cd5736026a</td>\n",
       "      <td>One element of an Ideal tragedy is having a co...</td>\n",
       "      <td>0.088882</td>\n",
       "      <td>-0.594710</td>\n",
       "      <td>One element of an ideal tragedy is having a co...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>39c16e</td>\n",
       "      <td>Summarize at least 3 elements of an ideal trag...</td>\n",
       "      <td>On Tragedy</td>\n",
       "      <td>Chapter 13 \\r\\nAs the sequel to what has alrea...</td>\n",
       "      <td>00d98b8ff756</td>\n",
       "      <td>The 3 ideal of tragedy is how complex you need...</td>\n",
       "      <td>-0.687288</td>\n",
       "      <td>-0.460886</td>\n",
       "      <td>The 3 ideal of tragedy is how complex you need...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  prompt_id                                    prompt_question prompt_title  \\\n",
       "0    39c16e  Summarize at least 3 elements of an ideal trag...   On Tragedy   \n",
       "1    39c16e  Summarize at least 3 elements of an ideal trag...   On Tragedy   \n",
       "2    39c16e  Summarize at least 3 elements of an ideal trag...   On Tragedy   \n",
       "3    39c16e  Summarize at least 3 elements of an ideal trag...   On Tragedy   \n",
       "4    39c16e  Summarize at least 3 elements of an ideal trag...   On Tragedy   \n",
       "\n",
       "                                         prompt_text    student_id  \\\n",
       "0  Chapter 13 \\r\\nAs the sequel to what has alrea...  00791789cc1f   \n",
       "1  Chapter 13 \\r\\nAs the sequel to what has alrea...  0086ef22de8f   \n",
       "2  Chapter 13 \\r\\nAs the sequel to what has alrea...  0094589c7a22   \n",
       "3  Chapter 13 \\r\\nAs the sequel to what has alrea...  00cd5736026a   \n",
       "4  Chapter 13 \\r\\nAs the sequel to what has alrea...  00d98b8ff756   \n",
       "\n",
       "                                                text   content   wording  \\\n",
       "0  1 element of an ideal tragedy is that it shoul... -0.210614 -0.471415   \n",
       "1  The three elements of an ideal tragedy are:  H... -0.970237 -0.417058   \n",
       "2  Aristotle states that an ideal tragedy should ... -0.387791 -0.584181   \n",
       "3  One element of an Ideal tragedy is having a co...  0.088882 -0.594710   \n",
       "4  The 3 ideal of tragedy is how complex you need... -0.687288 -0.460886   \n",
       "\n",
       "                                      corrected_text  fold  \n",
       "0  One element of an ideal tragedy is that it sho...     0  \n",
       "1  The three elements of an ideal tragedy are  Ha...     0  \n",
       "2  Aristotle states that an ideal tragedy should ...     0  \n",
       "3  One element of an ideal tragedy is having a co...     0  \n",
       "4  The 3 ideal of tragedy is how complex you need...     0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id2fold = {\n",
    "            \"39c16e\": 0,\n",
    "            \"814d6b\": 1,\n",
    "            \"3b9047\": 2,\n",
    "            \"ebad26\": 3,\n",
    "        }\n",
    "df[\"fold\"] = df[\"prompt_id\"].map(id2fold)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [1, 2, 2], 'token_type_ids': [0, 0, 0], 'attention_mask': [1, 1, 1]}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer(tokenizer.sep_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 113/7165 [00:00<00:12, 578.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7165/7165 [00:14<00:00, 510.28it/s]\n"
     ]
    }
   ],
   "source": [
    "columns = [ \"text\", \"prompt_title\", \"prompt_question\", \"prompt_text\"]\n",
    "fold_length_dict = {k:[] for k in range(4)}\n",
    "\n",
    "for i, row in tqdm(df.iterrows(), total = len(df)):\n",
    "    text_to_tokenize = f\" {tokenizer.sep_token} \".join([row[col] for col in columns])\n",
    "    tokens = tokenizer(text_to_tokenize)[\"input_ids\"]\n",
    "    fold_length_dict[int(row[\"fold\"])].append(len(tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold : 0\n",
      "Mean of tokens: 814.0636849781234\n",
      "Median of tokens: 798.0\n",
      "Max length of tokens: 1481\n",
      "Min length of tokens: 767\n",
      "Fold : 1\n",
      "Mean of tokens: 778.9963735267453\n",
      "Median of tokens: 763.0\n",
      "Max length of tokens: 1162\n",
      "Min length of tokens: 723\n",
      "Fold : 2\n",
      "Mean of tokens: 790.1393728222996\n",
      "Median of tokens: 767.0\n",
      "Max length of tokens: 1508\n",
      "Min length of tokens: 715\n",
      "Fold : 3\n",
      "Mean of tokens: 1257.1728456913827\n",
      "Median of tokens: 1237.0\n",
      "Max length of tokens: 1790\n",
      "Min length of tokens: 1190\n"
     ]
    }
   ],
   "source": [
    "for k, v in fold_length_dict.items():\n",
    "    print(f\"Fold : {k}\")\n",
    "    print(f\"Mean of tokens: {np.mean(v)}\")\n",
    "    print(f\"Median of tokens: {np.median(v)}\")\n",
    "    print(f\"Max length of tokens: {np.max(v)}\")\n",
    "    print(f\"Min length of tokens: {np.min(v)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
