hydra:
  job:
    chdir: False

train_summary_file: "../data/summaries_train.csv"
train_prompt_file : "../data/prompts_train.csv"
batch_size: 8
valid_batch_size: 8
epochs: 4
lr: 2e-5
max_len: 1800
model_name: "microsoft/deberta-v3-large"
hidden_dropout_prob: 0.1
layer_norm_eps: 1e-7
gradient_accumulation_steps: 1
gradient_checkpointing_enable: True
warmup_ratio: 0.1
max_grad_norm: 10.0
target_columns: ['content', 'wording']
num_classes: 2
seed: 42
device: "cuda"
multi_gpu: False
use_wandb: True
project_name: "commonlit-kaggle"
metadata_path: "../data/commonlit_texts.csv"
output_dir: "../output/"
repo_id: ""
freeze: True
start_freeze_layer: 0
end_freeze_layer: 12
llrd: 1
train_whole_dataset: False
correct_spelling: False
use_prompt_text: False
columns_to_use: ["text", "prompt_title","prompt_question", "prompt_text"]
clean_text: False
compile: False
use_awp: False
awp_start_epoch: 2
adv_lr: 1e-5
adv_eps: 1e-3
criterion: "mcrmse" # rmse, mcrmse, rdrop
noisy_tune: False
rdrop_alpha: 1.0
add_rank_loss: False
rank_loss_weight: 0.1
pooling: "cls"
concat_pooling: "cls"
use_gpl_checkpoint: False
gpl_repo_id: "jashdalvi/commonlit-kaggle-gpl-deberta-v3-large"